{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Forward Pass**"
      ],
      "metadata": {
        "id": "uzgXDJ6AQsnf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4MG4Y9RIQlFj"
      },
      "outputs": [],
      "source": [
        "# dependencies\n",
        "import torch\n",
        "import triton\n",
        "import triton.language as tl\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@triton.jit\n",
        "def _attn_fwd_inner(\n",
        "    O_block,\n",
        "    l_i,\n",
        "    m_i,\n",
        "    Q_block,\n",
        "    K_block_ptr,\n",
        "    V_block_ptr,\n",
        "    block_index_q,\n",
        "    softmax_scale,\n",
        "    BLOCK_SIZE_Q: tl.constexpr,\n",
        "    BLOCK_SIZE_KV: tl.constexpr,\n",
        "    STAGE: tl.constexpr,\n",
        "    offs_q: tl.constexpr,\n",
        "    offs_kv: tl.constexpr,\n",
        "    SEQ_LEN: tl.constexpr,\n",
        "    ):\n",
        "  # range of values handled by this stage\n",
        "  if STAGE == 1:\n",
        "    # From 0 to the left of the diagonal (in the notebook)\n",
        "    lo, hi = 0, block_index_q * BLOCK_SIZE_Q\n",
        "  elif STAGE == 2:\n",
        "    # Used only for the block in which there is transition between non-masked and masked keys\n",
        "    lo, hi = block_index_q * BLOCK_SIZE_Q, (block_index_q + 1) * BLOCK_SIZE_Q\n",
        "    lo = tl.multiple_of(lo, BLOCK_SIZE_Q)\n",
        "  else:\n",
        "    # Only used for non-causal attention\n",
        "    lo, hi = 0, SEQ_LEN\n",
        "\n",
        "  # point it to first K, V block\n",
        "  K_block_ptr = tl.advance(K_block_ptr, (0, lo))\n",
        "  V_block_ptr = tl.advance(V_block_ptr, (lo, 0))\n",
        "\n",
        "  # loop over k, v and update accumulator\n",
        "  for start_kv in range(lo, hi, BLOCK_SIZE_KV):\n",
        "    # Just let the compiler know that start_n is a multiple of BLOCK_N, so the compiler can do optimizations\n",
        "    start_kv = tl.multiple_of(start_kv, BLOCK_SIZE_KV)\n",
        "\n",
        "    # -- compute qk ----\n",
        "    K_block = tl.load(K_block_ptr)\n",
        "    QK_block = tl.dot(Q_block, K_block)\n",
        "\n",
        "    if STAGE == 2:\n",
        "      mask = offs_q[:, None] >= (start_kv + offs_kv[None, :])\n",
        "      QK_block = QK_block * softmax_scale + tl.where(mask, 0, -1.0e6)\n",
        "      m_ij = tl.maximum(m_i, tl.max(QK_block, 1))\n",
        "      QK_block -= m_ij[:, None]\n",
        "    else:\n",
        "      # Compute the maximum value of qk or keep the old max value\n",
        "      m_ij = tl.maximum(m_i, tl.max(QK_block, 1) * softmax_scale)\n",
        "      QK_block = QK_block * softmax_scale - m_ij[:, None]\n",
        "    # Compute the exponential of each dot product, so now we are computing exp(qk_ij - m_ij)\n",
        "    P_block = tl.math.exp(QK_block)\n",
        "\n",
        "    # Compute the sum by rows of the attention scores\n",
        "    l_ij = tl.sum(P_block, 1)\n",
        "\n",
        "    # This is the correction factor for the previous l_i\n",
        "    alpha = tl.math.exp(m_i - m_ij)\n",
        "\n",
        "    # Apply the correction factor to the previous l_i and add the new l_ij\n",
        "    l_i = l_i * alpha + l_ij\n",
        "\n",
        "    V_block = tl.load(V_block_ptr)\n",
        "    P_block = P_block.to(tl.float16)\n",
        "\n",
        "    # This computes the following: O_new = P x V + O_old * alpha\n",
        "    O_block = O_block * alpha[:, None]\n",
        "    O_block = tl.dot(P_block, V_block, O_block) # O_block += P_block @ V_block\n",
        "\n",
        "    m_i = m_ij\n",
        "\n",
        "    V_block_ptr = tl.advance(V_block_ptr, (BLOCK_SIZE_KV, 0)) # V[SEQ_LEN, HEAD_DIM]\n",
        "    K_block_ptr = tl.advance(K_block_ptr, (0, BLOCK_SIZE_KV)) # K[HEAD_DIM, SEQ_LEN]\n",
        "\n",
        "  return O_block, l_i, m_i"
      ],
      "metadata": {
        "id": "uXVj7u0Ebyj8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@triton.autotune(\n",
        "    [\n",
        "        triton.Config(\n",
        "            {\"BLOCK_SIZE_Q\": BLOCK_SIZE_Q, \"BLOCK_SIZE_KV\": BLOCK_SIZE_KV},\n",
        "            num_stages=num_stages,\n",
        "            num_warps=num_warps,\n",
        "        )\n",
        "        for BLOCK_SIZE_Q in [64, 128]\n",
        "        for BLOCK_SIZE_KV in [32, 64]\n",
        "        for num_stages in ([3, 4, 7])\n",
        "        for num_warps in [2, 4]\n",
        "    ],\n",
        "    key=[\"SEQ_LEN\", \"HEAD_DIM\"],\n",
        "  )\n",
        "# Triton kernel signature - makes the python method a triton kernel\n",
        "@triton.jit\n",
        "def _attn_fwd(\n",
        "    Q,  # BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM # This is a pointer but we need to do something like Q[index_batch, index_head, :, :]\n",
        "    # done by qvk_offset\n",
        "    K,  # BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM\n",
        "    V,  # BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM\n",
        "    softmax_scale,\n",
        "    M,  # BATCH_SIZE, NUM_HEADS, SEQ_LEN\n",
        "    O,  # BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM\n",
        "    stride_Q_batch,\n",
        "    stride_Q_head,\n",
        "    stride_Q_seq,\n",
        "    stride_Q_dim,\n",
        "    stride_K_batch,\n",
        "    stride_K_head,\n",
        "    stride_K_seq,\n",
        "    stride_K_dim,\n",
        "    stride_V_batch,\n",
        "    stride_V_head,\n",
        "    stride_V_seq,\n",
        "    stride_V_dim,\n",
        "    stride_O_batch,\n",
        "    stride_O_head,\n",
        "    stride_O_seq,\n",
        "    stride_O_dim,\n",
        "    BATCH_SIZE,\n",
        "    NUM_HEADS: tl.constexpr,\n",
        "    SEQ_LEN: tl.constexpr,\n",
        "    HEAD_DIM: tl.constexpr,\n",
        "    BLOCK_SIZE_Q: tl.constexpr,\n",
        "    BLOCK_SIZE_KV: tl.constexpr,\n",
        "    STAGE: tl.constexpr,\n",
        "):\n",
        "  tl.static_assert(BLOCK_SIZE_KV <= HEAD_DIM)\n",
        "\n",
        "  # This indicate which block in the sequence length to process\n",
        "  block_index_q = tl.program_id(0)\n",
        "\n",
        "  # This indicates which head and batch to process. Each program is associated with a single head of a single batch\n",
        "  index_batch_head = tl.program_id(1)\n",
        "  # This indicate which batch this program is associated with (each batch has NUM_HEADS heads)\n",
        "  index_batch = index_batch_head // NUM_HEADS\n",
        "  # This indicate the position of the head in the batch\n",
        "  index_head = index_batch_head % NUM_HEADS\n",
        "\n",
        "  qvk_offset = (\n",
        "      index_batch.to(tl.int64) * stride_Q_batch\n",
        "      + index_head.to(tl.int64) * stride_Q_head\n",
        "  )\n",
        "\n",
        "  # Make block pointer - takes a ptr # Q[index_batch, index_batch, block_index_q * BLOCK_SIZE_Q, :]\n",
        "  Q_block_ptr = tl.make_block_ptr(\n",
        "      base=Q + qvk_offset,\n",
        "      shape=(SEQ_LEN, HEAD_DIM),\n",
        "      strides=(stride_Q_seq, stride_Q_dim),\n",
        "      offsets=(block_index_q * BLOCK_SIZE_Q, 0),\n",
        "      block_shape=(BLOCK_SIZE_Q, HEAD_DIM),\n",
        "      order=(1, 0),\n",
        "  )\n",
        "\n",
        "  # We are not skipping anything on sequence, HEAD_DIIM\n",
        "  V_block_ptr = tl.make_block_ptr( # V[index_batch, index_head, :, :]\n",
        "      base=V + qvk_offset,\n",
        "      shape=(SEQ_LEN, HEAD_DIM),\n",
        "      strides=(stride_V_seq, stride_V_dim),\n",
        "      offsets=(0, 0),\n",
        "      block_shape=(BLOCK_SIZE_KV, HEAD_DIM),\n",
        "      order=(1, 0),\n",
        "  )\n",
        "\n",
        "  K_block_ptr = tl.make_block_ptr( # K[index_batch, index_head, :, :]\n",
        "      base=K + qvk_offset,\n",
        "      shape=(HEAD_DIM, SEQ_LEN),\n",
        "      strides=(\n",
        "          stride_K_dim,\n",
        "          stride_K_seq,\n",
        "      ),  # We invert the strides w.r.t Q, so we transpose the matrix\n",
        "      offsets=(0, 0),\n",
        "      block_shape=(HEAD_DIM, BLOCK_SIZE_KV),\n",
        "      order=(0, 1),\n",
        "  )\n",
        "\n",
        "  O_block_ptr = tl.make_block_ptr( # O[index_batch, index_batch, block_index_q * BLOCK_SIZE_Q, :]\n",
        "      base=O + qvk_offset,\n",
        "      shape=(SEQ_LEN, HEAD_DIM),\n",
        "      strides=(stride_O_seq, stride_O_dim),\n",
        "      offsets=(block_index_q * BLOCK_SIZE_Q, 0),\n",
        "      block_shape=(BLOCK_SIZE_Q, HEAD_DIM),\n",
        "      order=(1, 0),\n",
        "  )\n",
        "  # offs_q: the offsets for the tokens in the Q to process\n",
        "  offs_q = block_index_q * BLOCK_SIZE_Q + tl.arange(0, BLOCK_SIZE_Q)\n",
        "\n",
        "  # offs_kv: the offsets for the tokens in the K and V sequence to process\n",
        "  offs_kv = tl.arange(0, BLOCK_SIZE_KV)\n",
        "\n",
        "  # m_i: the running maximum. We have one for each query\n",
        "  m_i = tl.zeros([BLOCK_SIZE_Q], dtype=tl.float32) - float(\"inf\")\n",
        "\n",
        "  # l_i: the running sum. We have one for each query (as we sum the attention scores by rows)\n",
        "  l_i = tl.zeros([BLOCK_SIZE_Q], dtype=tl.float32) + 1.0 # 1.0 to make it stable\n",
        "\n",
        "  # acc: the accumulator for the output, which is a group of rows of the O matrix\n",
        "  O_block = tl.zeros([BLOCK_SIZE_Q, HEAD_DIM], dtype=tl.float32)\n",
        "\n",
        "  # load it from HBM to shared memory\n",
        "  Q_block = tl.load(Q_block_ptr)\n",
        "\n",
        "\n",
        "  # Causal Attention: We dont want Q to attend K that come after it\n",
        "  if STAGE == 1 or STAGE == 3:\n",
        "    # This step runs for non-causal attention or for the blocks to the left of the diagonal in the causal attention\n",
        "    # _attn_fwd_inner this inner loop needs to go trhough all K, V blocks\n",
        "    # For each K, V it needs to fix previous calculated block\n",
        "    O_block, l_i, m_i = _attn_fwd_inner(\n",
        "          O_block,\n",
        "          l_i,\n",
        "          m_i,\n",
        "          Q_block,\n",
        "          K_block_ptr,\n",
        "          V_block_ptr,\n",
        "          block_index_q,\n",
        "          softmax_scale,\n",
        "          BLOCK_SIZE_Q,\n",
        "          BLOCK_SIZE_KV,\n",
        "          4 - STAGE,\n",
        "          offs_q,\n",
        "          offs_kv,\n",
        "          SEQ_LEN,\n",
        "      )\n",
        "  if STAGE == 3:\n",
        "    # This step runs for the blocks to the right of the diagonal in the causal attention\n",
        "    O_block, l_i, m_i = _attn_fwd_inner(\n",
        "          O_block,\n",
        "          l_i,\n",
        "          m_i,\n",
        "          Q_block,\n",
        "          K_block_ptr,\n",
        "          V_block_ptr,\n",
        "          block_index_q,\n",
        "          softmax_scale,\n",
        "          BLOCK_SIZE_Q,\n",
        "          BLOCK_SIZE_KV,\n",
        "          2,\n",
        "          offs_q,\n",
        "          offs_kv,\n",
        "          SEQ_LEN,\n",
        "      )\n",
        "\n",
        "  m_i += tl.math.log(\n",
        "      l_i\n",
        "  ) # This is needed to compute the logsumexp for the backwards pass\n",
        "  O_block = O_block / l_i[:, None]\n",
        "\n",
        "  # Skipping each batch and each head\n",
        "  # M = first element of entire tensor\n",
        "  m_ptrs = M + index_batch_head * SEQ_LEN + offs_q\n",
        "  tl.store(m_ptrs, m_i)\n",
        "  tl.store(O_block_ptr, O_block.to(O.type.element_ty))"
      ],
      "metadata": {
        "id": "1ON6dDHTpeTh"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@triton.jit\n",
        "def _attn_bwd_preprocess(\n",
        "    O,\n",
        "    dO,\n",
        "    D, # (BATCH_SIZE, NUM_HEADS, SEQ_LEN)\n",
        "    SEQ_LEN,\n",
        "    BLOCK_SIZE_Q: tl.constexpr,\n",
        "    HEAD_DIM: tl.constexpr,):\n",
        "\n",
        "  block_index_q = tl.program_id(0)\n",
        "  offs_q = block_index_q * BLOCK_SIZE_Q + tl.arange(0, BLOCK_SIZE_Q)\n",
        "  index_batch_head = tl.program_id(1)\n",
        "  offs_dim = tl.arange(0, HEAD_DIM)\n",
        "\n",
        "  # Load a single block of BLOCK_SIZE_Q rows of O\n",
        "  O_block = tl.load( # O [BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM]\n",
        "        O\n",
        "        + index_batch_head * HEAD_DIM * SEQ_LEN\n",
        "        + offs_q[:, None] * HEAD_DIM\n",
        "        + offs_dim[None, :]\n",
        "  )\n",
        "\n",
        "  # Load a single block of BLOCK_SIZE_Q (same size O Block) rows of dO\n",
        "  dO_block = tl.load(\n",
        "        dO\n",
        "        + index_batch_head * HEAD_DIM * SEQ_LEN\n",
        "        + offs_q[:, None] * HEAD_DIM\n",
        "        + offs_dim[None, :]\n",
        "  ).to(tl.float32)\n",
        "\n",
        "  D_block = tl.sum(dO_block * O_block, axis=1)  # Shape: (BLOCK_SIZE_Q,)\n",
        "  # Store the D block\n",
        "  D_block_ptrs = D + index_batch_head * SEQ_LEN + offs_q\n",
        "  tl.store(D_block_ptrs, D_block)"
      ],
      "metadata": {
        "id": "8m9CSv58CBiB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@triton.jit\n",
        "def _attn_bwd_dk_dv(\n",
        "  Q,\n",
        "  K,\n",
        "  V,\n",
        "  softmax_scale,\n",
        "  dO,\n",
        "  dQ,\n",
        "  dK,\n",
        "  dV,\n",
        "  M,\n",
        "  D,\n",
        "  stride_batch,\n",
        "  stride_head,\n",
        "  stride_seq,\n",
        "  stride_dim,\n",
        "  NUM_HEADS,\n",
        "  SEQ_LEN,\n",
        "  BLOCK_Q: tl.constexpr,\n",
        "  BLOCK_KV: tl.constexpr,\n",
        "  HEAD_DIM: tl.constexpr,\n",
        "  STAGE: tl.constexpr,\n",
        "):\n",
        "  index_batch_head = tl.program_id(2)\n",
        "  index_batch = index_batch_head // NUM_HEADS\n",
        "  index_head = index_batch_head % NUM_HEADS\n",
        "  offset_batch_head = (stride_batch * index_batch + stride_head * index_head).to(\n",
        "      tl.int64\n",
        "  )\n",
        "  # This is the offset that allows us to select the right sequence given the batch and head.\n",
        "  offset_batch_head_seq = (index_batch_head * SEQ_LEN).to(tl.int64)\n",
        "\n",
        "  # Make sure the pointers are in the right place w.r.t batch and head\n",
        "  # The reason we don't access the blocks through make_block_ptr is because we need to use the range of offsets to apply the masking\n",
        "  Q += offset_batch_head\n",
        "  K += offset_batch_head # [Batch, NUM_HEADS, SEQ, HEAD_DIM]\n",
        "  V += offset_batch_head\n",
        "  dO += offset_batch_head\n",
        "  dQ += offset_batch_head\n",
        "  dK += offset_batch_head\n",
        "  dV += offset_batch_head\n",
        "\n",
        "  # Make sure the pointers are in the right place w.r.t batch, head and sequence\n",
        "  M += offset_batch_head_seq\n",
        "  D += offset_batch_head_seq\n",
        "\n",
        "  # load scales\n",
        "  offs_dim = tl.arange(0, HEAD_DIM)\n",
        "\n",
        "  index_block_kv = tl.program_id(0)\n",
        "  start_kv = index_block_kv * BLOCK_KV\n",
        "\n",
        "  offs_kv = start_kv + tl.arange(0, BLOCK_KV)\n",
        "\n",
        "  dV_block = tl.zeros([BLOCK_KV, HEAD_DIM], dtype=tl.float32)\n",
        "  dK_block = tl.zeros([BLOCK_KV, HEAD_DIM], dtype=tl.float32)\n",
        "\n",
        "  # load K and V: they stay in SRAM throughout the inner loop.\n",
        "  K_block = tl.load(\n",
        "      K + offs_kv[:, None] * stride_seq + offs_dim[None, :] * stride_dim\n",
        "  )  # Shape: (BLOCK_KV1, HEAD_DIM)\n",
        "  V_block = tl.load(\n",
        "      V + offs_kv[:, None] * stride_seq + offs_dim[None, :] * stride_dim\n",
        "  )  # Shape: (BLOCK_KV1, HEAD_DIM)\n",
        "\n",
        "  offs_q = tl.arange(0, BLOCK_Q)\n",
        "\n",
        "  # 0 + (0, 1, 2, 3)\n",
        "  # 4 + (0, 1, 2, 3)\n",
        "  # 2 * 4 + (0, 1, 2, 3)\n",
        "  # 3 * 4 + (0, 1, 2, 3)\n",
        "\n",
        "  # We access the Q as a transposed array, so that's why we treat offs_q as a column vector ans offs_dim as a row vector\n",
        "  # This is equivalent to doing:\n",
        "  # q_ptrs = Q + offs_q[:, None] * stride_seq + offs_dim[None, :] * stride_dim\n",
        "  # qT_ptrs = tl.trans(q_ptrs)\n",
        "  # We point to the first BLOCK_Q rows of Q for both the qT and dO pointers, inside the for loop we will move forward by BLOCK_Q rows at each iteration.\n",
        "  qT_ptrs = Q + offs_q[None, :] * stride_seq + offs_dim[:, None] * stride_dim\n",
        "  dO_ptrs = dO + offs_q[:, None] * stride_seq + offs_dim[None, :] * stride_dim\n",
        "\n",
        "  # Iterates over the sequence dimension of the query\n",
        "  curr_q = 0\n",
        "  num_steps = SEQ_LEN // BLOCK_Q\n",
        "  for blk_idx in range(num_steps):\n",
        "      # Load a block of Q\n",
        "      qT_block = tl.load(qT_ptrs)\n",
        "      # Load the logsumexp values for the queries in the current block\n",
        "      offs_q = curr_q + tl.arange(0, BLOCK_Q)\n",
        "      m = tl.load(M + offs_q)\n",
        "\n",
        "      # This gives us (QK^T)^T = (K^T)^T(Q^T) = K(Q^T) = P^T\n",
        "      QK_T_block = softmax_scale * tl.dot(K_block, qT_block)\n",
        "      # We apply the softmax by using the logsumexp trick\n",
        "      P_T_block = tl.math.exp(QK_T_block - m[None, :])\n",
        "\n",
        "      if STAGE == 3:\n",
        "          # Autoregressive masking.\n",
        "          # mask is True for all values that DO NOT NEED TO BE MASKED\n",
        "          mask_block = (\n",
        "              offs_q[None, :] >= offs_kv[:, None]\n",
        "          )  # Shape: (BLOCK_KV1, BLOCK_Q1)\n",
        "          # Replace all the masked values with 0.\n",
        "          # In this case we do not need to mask with -Inf before applying the softmax since we already computed the normalization factors (stored in \"m\")\n",
        "          P_T_block = tl.where(mask_block, P_T_block, 0.0)\n",
        "\n",
        "      dO_block = tl.load(dO_ptrs)\n",
        "      # According to the formula: dV_new = dV_old + P^T x dO, where x is the matrix multiplication\n",
        "      dV_block += tl.dot(P_T_block.to(tl.float16), dO_block)\n",
        "\n",
        "      # Delta = rowsum(O * dO) where * is the element-wise product\n",
        "      Di = tl.load(D + offs_q)\n",
        "\n",
        "      # dP = dO x V^T, so dP^T = V x dO^T\n",
        "      # Where x is the matrix multiplication\n",
        "      dpT_block = tl.dot(V_block, tl.trans(dO_block)).to(tl.float32)\n",
        "\n",
        "      # We know that dS = P * (dP - Delta), so dS^T = P^T * (dP^T - Delta^T)\n",
        "\n",
        "      dS_T_block = P_T_block * (dpT_block - Di[None, :])\n",
        "      dS_T_block = dS_T_block.to(tl.float16)\n",
        "\n",
        "      # According to the formula on the paper: dK_new = dK_old + dS^T x Q\n",
        "      dK_block += softmax_scale * tl.dot(dS_T_block, tl.trans(qT_block))\n",
        "      # Increment pointers.\n",
        "      curr_q += BLOCK_Q\n",
        "      qT_ptrs += BLOCK_Q * stride_seq\n",
        "      dO_ptrs += BLOCK_Q * stride_seq\n",
        "\n",
        "  # Write back dV.\n",
        "  dV_block_ptrs = dV + offs_kv[:, None] * stride_seq + offs_dim[None, :] * stride_dim\n",
        "  tl.store(dV_block_ptrs, dV_block)\n",
        "\n",
        "  # Write back dK.\n",
        "  dK_block_ptrs = dK + offs_kv[:, None] * stride_seq + offs_dim[None, :] * stride_dim\n",
        "  tl.store(dK_block_ptrs, dK_block)"
      ],
      "metadata": {
        "id": "tiixfdXeJfmQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@triton.jit\n",
        "def _attn_bwd_dq(\n",
        "  Q,\n",
        "  K,\n",
        "  V,\n",
        "  softmax_scale,\n",
        "  dO,\n",
        "  dQ,\n",
        "  dK,\n",
        "  dV,\n",
        "  M,\n",
        "  D,\n",
        "  stride_batch,\n",
        "  stride_head,\n",
        "  stride_seq,\n",
        "  stride_dim,\n",
        "  NUM_HEADS,\n",
        "  SEQ_LEN,\n",
        "  BLOCK_Q: tl.constexpr,\n",
        "  BLOCK_KV: tl.constexpr,\n",
        "  HEAD_DIM: tl.constexpr,\n",
        "  STAGE: tl.constexpr,\n",
        "):\n",
        "  index_batch_head = tl.program_id(2)\n",
        "  index_batch = index_batch_head // NUM_HEADS\n",
        "  index_head = index_batch_head % NUM_HEADS\n",
        "  offset_batch_head = (stride_batch * index_batch + stride_head * index_head).to(\n",
        "      tl.int64\n",
        "  )\n",
        "  # This is the offset that allows us to select the right sequence given the batch and head.\n",
        "  offset_batch_head_seq = (index_batch_head * SEQ_LEN).to(tl.int64)\n",
        "\n",
        "  # Make sure the pointers are in the right place w.r.t batch and head\n",
        "  # The reason we don't access the blocks through make_block_ptr is because we need to use the range of offsets to apply the masking\n",
        "  Q += offset_batch_head\n",
        "  K += offset_batch_head\n",
        "  V += offset_batch_head\n",
        "  dO += offset_batch_head\n",
        "  dQ += offset_batch_head\n",
        "  dK += offset_batch_head\n",
        "  dV += offset_batch_head\n",
        "\n",
        "  # Make sure the pointers are in the right place w.r.t batch, head and sequence\n",
        "  M += offset_batch_head_seq\n",
        "  D += offset_batch_head_seq\n",
        "\n",
        "  # load scales\n",
        "  offs_dim = tl.arange(0, HEAD_DIM)\n",
        "\n",
        "  index_block_kv = tl.program_id(0)\n",
        "\n",
        "  start_q = index_block_kv * BLOCK_Q\n",
        "  offs_q = start_q + tl.arange(0, BLOCK_Q)\n",
        "\n",
        "  Q_block = tl.load(Q + offs_q[:, None] * stride_seq + offs_dim[None, :] * stride_dim)\n",
        "  dQ_block = tl.zeros([BLOCK_Q, HEAD_DIM], dtype=tl.float32)\n",
        "  dO_block = tl.load(\n",
        "      dO + offs_q[:, None] * stride_seq + offs_dim[None, :] * stride_dim\n",
        "  )\n",
        "\n",
        "  M_block = tl.load(M + offs_q)\n",
        "  M_block = M_block[:, None]\n",
        "\n",
        "  offs_kv = tl.arange(0, BLOCK_KV)\n",
        "\n",
        "  # We access the K and V as transposed blocks\n",
        "  kT_ptrs = K + offs_kv[None, :] * stride_seq + offs_dim[:, None] * stride_dim\n",
        "  vT_ptrs = V + offs_kv[None, :] * stride_seq + offs_dim[:, None] * stride_dim\n",
        "\n",
        "  Di = tl.load(D + offs_q)\n",
        "\n",
        "  curr_kv = 0\n",
        "  num_steps = SEQ_LEN // BLOCK_KV\n",
        "  for blk_idx in range(num_steps):\n",
        "      K_T_block = tl.load(kT_ptrs)\n",
        "      V_T_block = tl.load(vT_ptrs)\n",
        "      QK_block = softmax_scale * tl.dot(Q_block, K_T_block)\n",
        "      P_block = tl.math.exp(QK_block - M_block)\n",
        "\n",
        "      if STAGE == 3:\n",
        "          # Autoregressive masking.\n",
        "          offs_kv = curr_kv + tl.arange(0, BLOCK_KV)\n",
        "          mask_block = offs_q[:, None] >= offs_kv[None, :]\n",
        "          P_block = tl.where(mask_block, P_block, 0.0)\n",
        "\n",
        "      # Compute dP and dS.\n",
        "      dP_block = tl.dot(dO_block, V_T_block).to(tl.float32)\n",
        "      dS_block = P_block * (dP_block - Di[:, None])\n",
        "      dS_block = dS_block.to(tl.float16)\n",
        "      # Compute dQ.\n",
        "      # NOTE: We need to de-scale dq in the end, because kT was pre-scaled.\n",
        "      dQ_block += softmax_scale * tl.dot(dS_block, tl.trans(K_T_block))\n",
        "      # Increment pointers.\n",
        "      curr_kv += BLOCK_KV\n",
        "      kT_ptrs += BLOCK_KV * stride_seq\n",
        "      vT_ptrs += BLOCK_KV * stride_seq\n",
        "\n",
        "  dQ_block_ptrs = dQ + offs_q[:, None] * stride_seq + offs_dim[None, :] * stride_dim\n",
        "  tl.store(dQ_block_ptrs, dQ_block)"
      ],
      "metadata": {
        "id": "3dNjQpxbR49x"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TritonAttention(torch.autograd.Function):\n",
        "\n",
        "  @staticmethod\n",
        "  # ctx = context storage for backward which is stored while forward\n",
        "  def forward(ctx, Q, K, V, causal, softmax_scale):\n",
        "    HEAD_DIM_Q, HEAD_DIM_K = Q.shape[-1], K.shape[-1]\n",
        "    HEAD_DIM_V = V.shape[-1]\n",
        "\n",
        "    BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM = Q.shape\n",
        "    assert HEAD_DIM == HEAD_DIM_Q and HEAD_DIM_K == HEAD_DIM_V\n",
        "\n",
        "    O = torch.empty_like(Q)\n",
        "    stage = 3 if causal else 1\n",
        "\n",
        "    # launch grid (tile) - how many parallel process to be launched\n",
        "    grid = lambda args: (\n",
        "        # ceil(SEQ_LEN / BLOCK_SIZE_Q)\n",
        "        triton.cdiv(SEQ_LEN, args[\"BLOCK_SIZE_Q\"]), # which group of queries we are going to work with (how many tiles along the sequence)\n",
        "        BATCH_SIZE * NUM_HEADS, # which head of which batch element we are going to work with? (one “row” per (batch, head) pair)\n",
        "        1,\n",
        "    )\n",
        "\n",
        "    # M is the logsumexp for backward pass, one for each query\n",
        "    M = torch.empty(\n",
        "        (BATCH_SIZE, NUM_HEADS, SEQ_LEN), device=Q.device, dtype=torch.float32\n",
        "    )\n",
        "\n",
        "    # Triton Kernel\n",
        "    _attn_fwd[grid](\n",
        "            Q=Q, # just starting pointer\n",
        "            K=K,\n",
        "            V=V,\n",
        "            softmax_scale=softmax_scale,\n",
        "            M=M,\n",
        "            O=O,\n",
        "            stride_Q_batch=Q.stride(0),\n",
        "            stride_Q_head=Q.stride(1),\n",
        "            stride_Q_seq=Q.stride(2),\n",
        "            stride_Q_dim=Q.stride(3),\n",
        "            stride_K_batch=K.stride(0),\n",
        "            stride_K_head=K.stride(1),\n",
        "            stride_K_seq=K.stride(2),\n",
        "            stride_K_dim=K.stride(3),\n",
        "            stride_V_batch=V.stride(0),\n",
        "            stride_V_head=V.stride(1),\n",
        "            stride_V_seq=V.stride(2),\n",
        "            stride_V_dim=V.stride(3),\n",
        "            stride_O_batch=O.stride(0),\n",
        "            stride_O_head=O.stride(1),\n",
        "            stride_O_seq=O.stride(2),\n",
        "            stride_O_dim=O.stride(3),\n",
        "            BATCH_SIZE=Q.shape[0],\n",
        "            NUM_HEADS=Q.shape[1],\n",
        "            SEQ_LEN=Q.shape[2],\n",
        "            HEAD_DIM=HEAD_DIM_K,\n",
        "            STAGE=stage,\n",
        "        )\n",
        "\n",
        "    ctx.save_for_backward(Q, K, V, O, M)\n",
        "    ctx.grid = grid\n",
        "    ctx.softmax_scale = softmax_scale\n",
        "    ctx.HEAD_DIM = HEAD_DIM_K\n",
        "    ctx.causal = causal\n",
        "    return O\n",
        "\n",
        "  @staticmethod\n",
        "  def backward(ctx, dO):\n",
        "    # extract Q, K, V, O, M from ctx\n",
        "    Q, K, V, O, M = ctx.saved_tensors\n",
        "\n",
        "    assert dO.is_contiguous()\n",
        "    assert Q.stride() == K.stride() == V.stride() == O.stride() == dO.stride()\n",
        "    dQ = torch.empty_like(Q)\n",
        "    dK = torch.empty_like(K)\n",
        "    dV = torch.empty_like(V)\n",
        "\n",
        "    BATCH_SIZE, NUM_HEADS, SEQ_LEN = Q.shape[:3]\n",
        "    NUM_WARPS, NUM_STAGES = 4, 3\n",
        "    BLOCK_SIZE_MICRO, BLOCK_SIZE_MACRO = 32, 128\n",
        "\n",
        "    preprocess_grid = (SEQ_LEN // BLOCK_SIZE_MACRO, BATCH_SIZE * NUM_HEADS)\n",
        "    D = torch.empty_like(M)  # Shape: (BATCH_SIZE, NUM_HEADS, SEQ_LEN)\n",
        "\n",
        "    # Compute all the elements Di elements (see the paper)\n",
        "    # This Di depends only on O; Di is one for each of output elements in output of the attention\n",
        "    _attn_bwd_preprocess[preprocess_grid](\n",
        "        O=O,\n",
        "        dO=dO,\n",
        "        D=D,\n",
        "        SEQ_LEN=SEQ_LEN,\n",
        "        BLOCK_SIZE_Q=BLOCK_SIZE_MACRO,\n",
        "        HEAD_DIM=ctx.HEAD_DIM,\n",
        "    )\n",
        "\n",
        "    grid = (SEQ_LEN // BLOCK_SIZE_MACRO, 1, BATCH_SIZE * NUM_HEADS)\n",
        "    # fixed block: has macro number of thread blocks\n",
        "\n",
        "    stage = 3 if ctx.causal else 1\n",
        "\n",
        "    # Fix KV and iterate through all the Q blocks\n",
        "    _attn_bwd_dk_dv[grid](\n",
        "        Q=Q,\n",
        "        K=K,\n",
        "        V=V,\n",
        "        softmax_scale=ctx.softmax_scale,\n",
        "        dO=dO,\n",
        "        dQ=dQ,\n",
        "        dK=dK,\n",
        "        dV=dV,\n",
        "        M=M,\n",
        "        D=D,\n",
        "        stride_batch=Q.stride(0),\n",
        "        stride_head=Q.stride(1),\n",
        "        stride_seq=Q.stride(2),\n",
        "        stride_dim=Q.stride(3),\n",
        "        NUM_HEADS=NUM_HEADS,\n",
        "        SEQ_LEN=SEQ_LEN,\n",
        "        BLOCK_Q=BLOCK_SIZE_MICRO,\n",
        "        BLOCK_KV=BLOCK_SIZE_MACRO,\n",
        "        HEAD_DIM=ctx.HEAD_DIM,\n",
        "        STAGE=stage,\n",
        "        num_warps=NUM_WARPS,\n",
        "        num_stages=NUM_STAGES,\n",
        "    )\n",
        "\n",
        "    _attn_bwd_dq[grid](\n",
        "        Q=Q,\n",
        "        K=K,\n",
        "        V=V,\n",
        "        softmax_scale=ctx.softmax_scale,\n",
        "        dO=dO,\n",
        "        dQ=dQ,\n",
        "        dK=dK,\n",
        "        dV=dV,\n",
        "        M=M,\n",
        "        D=D,\n",
        "        stride_batch=Q.stride(0),\n",
        "        stride_head=Q.stride(1),\n",
        "        stride_seq=Q.stride(2),\n",
        "        stride_dim=Q.stride(3),\n",
        "        NUM_HEADS=NUM_HEADS,\n",
        "        SEQ_LEN=SEQ_LEN,\n",
        "        BLOCK_Q=BLOCK_SIZE_MACRO,\n",
        "        BLOCK_KV=BLOCK_SIZE_MICRO,\n",
        "        HEAD_DIM=ctx.HEAD_DIM,\n",
        "        STAGE=stage,\n",
        "        num_warps=NUM_WARPS,\n",
        "        num_stages=NUM_STAGES,\n",
        "    )\n",
        "\n",
        "    return dQ, dK, dV, None, None\n"
      ],
      "metadata": {
        "id": "08EuPiCufxsf"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialise query, key and value sequence\n",
        "def test_op(BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM, causal, dtype=torch.float16):\n",
        "  Q = (\n",
        "      torch.empty(\n",
        "          (BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM),\n",
        "          dtype=dtype, device=\"cuda\"\n",
        "      )\n",
        "      .normal_(mean=0.0, std=0.5)\n",
        "      .requires_grad_()\n",
        "  )\n",
        "  K = (\n",
        "      torch.empty(\n",
        "          (BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM),\n",
        "          dtype=dtype, device=\"cuda\"\n",
        "      )\n",
        "      .normal_(mean=0.0, std=0.5)\n",
        "      .requires_grad_()\n",
        "  )\n",
        "  V = (\n",
        "      torch.empty(\n",
        "          (BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM),\n",
        "          dtype=dtype, device=\"cuda\"\n",
        "      )\n",
        "      .normal_(mean=0.0, std=0.5)\n",
        "      .requires_grad_()\n",
        "  )\n",
        "  # scaling factor\n",
        "  # QK^t/sqrt(HEAD_DIM)\n",
        "  softmax_scale = 1 / (HEAD_DIM ** 0.5)\n",
        "  d0 = torch.randn_like(Q) # for backward\n",
        "  # Naive Attention\n",
        "  MASK = torch.tril(torch.ones((SEQ_LEN, SEQ_LEN), device = \"cuda\"))\n",
        "  P = torch.matmul(Q, K.transpose(2, 3)) * softmax_scale # swaps dim 2 with dim 3\n",
        "  if causal:\n",
        "    P[:, :, MASK == 0] = float(\"-inf\")\n",
        "  P = torch.softmax(P.float(), dim = -1).half()\n",
        "\n",
        "  ref_0 = torch.matmul(P, V)\n",
        "  ref_0.backward(d0)\n",
        "  ref_dV, V.grad = V.grad.clone(), None\n",
        "  ref_dK, K.grad = K.grad.clone(), None\n",
        "  ref_dQ, Q.grad = Q.grad.clone(), None\n",
        "\n",
        "  # Triton Implementation\n",
        "  tri_out = TritonAttention.apply(Q, K, V, causal, softmax_scale).half()\n",
        "  tri_out.backward(d0)\n",
        "  tri_dV, V.grad = V.grad.clone(), None\n",
        "  tri_dK, K.grad = K.grad.clone(), None\n",
        "  tri_dQ, Q.grad = Q.grad.clone(), None\n",
        "\n",
        "  # compare\n",
        "  rtol = 0.0 # relative tolerance\n",
        "  atol = 1e-2 # absolute tolerance\n",
        "  assert torch.allclose(ref_0, tri_out, rtol=rtol, atol=atol)\n",
        "  assert torch.allclose(ref_dV, tri_dV, rtol=rtol, atol=atol)\n",
        "  assert torch.allclose(ref_dK, tri_dK, rtol=rtol, atol=atol)\n",
        "  assert torch.allclose(ref_dQ, tri_dQ, rtol=rtol, atol=atol)"
      ],
      "metadata": {
        "id": "-eXw4dCPV6yx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    test_op(BATCH_SIZE=8, NUM_HEADS=8, SEQ_LEN=2048, HEAD_DIM=64, causal=True)\n",
        "    test_op(BATCH_SIZE=8, NUM_HEADS=8, SEQ_LEN=2048, HEAD_DIM=64, causal=False)\n",
        "    print(\"PASSED\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRIjNCVrq07n",
        "outputId": "e5300369-8f55-4cf2-f27c-5fe16d66ef66"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PASSED\n"
          ]
        }
      ]
    }
  ]
}